# v0.1.2 CSDN-Data Server Develop

## *Overview*

[TOC]

## Setup Environment

从一个新的 Ubuntu 上（也不完全新）配置环境到和 RPi 3B (Ubuntu MATE) 上的工作一样！

### Install depends

**Python libraries:**

```shell
### skip clone source code
$ mkvirtualenv CSDN-Data
(CSDN-Data)$ pip install django djangorestframework django-rest-auth
(CSDN-Data)$ pip install django-extensions
(CSDN-Data)$ pip install requests selenium BeautifulSoup4
(CSDN-Data)$ pip install redis
```



**Machine Software:**

```shell
# apt install chromium-browser
# apt install chromium-chromewebdriver
# apt install redis-server redis-tools
```



### django server with DB

**copy db.sqlite3 to new clone directory**

run `$ python manage.py runserver 0.0.0.0:8010` to check django work or not!

### Crawl work

1. `cd CSDNVisualizer/libCrawler/`
2. `vim ../../conf/handler_pagesource.py`
3. `./spider/daemonize_use_threadpool.py start`

request:

```
http://localhost:8010/CSDNCrawler/startcrawler/?username=qq_29757283
```

to check crawl could work or not.

### Setup Redis

为了使 “subject” 可以工作，redis 很重要！

#### Setup DB Name for UserIDs

```shell
$ redis-cli
> SELECT 1
[1]> SET DB_NAME CSDN-Data_UserID
```

#### Setup `zset` (RANK) Member with Score

```python
$ python manage.py shell_plus
# Shell Plus Model Imports
from CSDNCrawler.models import \
Article, Fans, Follow, Follows, UserID, VisualData
...

>>> ## basic check ##
>>> obj = UserID.objects.get(id=1)
>>> obj.__dict__
{'_state': ...,
 'id': 1,
 'user_id': 'qq_29757283',
 'register_date': ...,
 'name': 'RDpWTeHM',
 'visit': 20199,
 'rank': 52154}

>>> import redis
>>> r_db = redis.Redis(host='localhost', port=6379, db=1)
>>> objs = UserID.objects.all()
>>> for obj in objs:
        r_db.zadd("RANK", {obj.user_id: obj.rank})

>>> exit()
```

#### Verify Work

在上面 django server 和 Crawl 都 work （启动）的情况下：

```shell
$ ./subject.py
...
Ctrl+C to quit!!!
```



===done environment setup.



















