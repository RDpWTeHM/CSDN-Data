# v0.2.1 Monitor Develop Note



## *Overview*

[TOC]

------



## Folder Structure

```
super-spider/
|---- (power) crawllib/
|       |---- __init__.py
|       |---- resourcemanage.py
|        `--- tests/
|               `--- 20190211_CSDN_UserIndex_Reference.py
|
|---- (key) site/ <==> userindex.py
|                  |=> userblog.py
|                  `=> siteindex.py
|
|---- (online) online/
|       `---- __init__.py
|
|---- (brige) observers/
|       `---- __init__.py
|
 `--- new_main.py
```



## Summary

```shell
(CSDN-Data) super-spider $ python -O new_main.py -b Chrome
....
(CSDN-Data) super-spider $ 
```



## Develop Note

### 2019/02/11

#### 15:49

- 创建了本文档和索引到本文档的相关文档。
- 参考了 practice -> "super-spider" 的开发，设计了 Monitor 架构。
  - 由 (key) `userindex.py` 获取网页数据（其 power by `crawllib` module）。
  - 由 (bridge) observers 提交数据给 server（未完成开发 - 打印出来数据）！
  - 由 (online) 从 server 获取任务（对象）（与 server 的 manager 交互）（未完成）。

- 命令行指定使用的浏览器类型的方式在 `new_main.py` 中。
- Ctrl + C 停止信号捕获 - 暂时没用（在使用 `resourcemanage.py` 之后有用）。



#### 16:08 develop online module

```python
#### Terminal 1 ####
$ ipython
>>> from multiprocessing.connection import Listener
>>> serv = Listener(('', 2736), authkey=b'CSDN-Data')
>>> client = serv.accept()
# block
```



```shell
#### Terminal 2 ####
(CSDN-Data) $ python -O new_main.py -b Chrome
....
```



```python
>>> conn = client
>>> conn.recv()
'require task'
>>> try:
        conn.send('qq_29757283')
        while True:
            print(conn.recv())
    except EOFError:
        print("finished")
'finished'
>>>
```







